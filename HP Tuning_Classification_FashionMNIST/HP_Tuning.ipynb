{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# HP Tuning\n",
        "\n",
        "Use the Keras Tuner library to perform hyperparameter tuning on a Classification neural network model. (to classify Fashion MNIST dataset classes)"
      ],
      "metadata": {
        "id": "38yUSlqbC6mb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist"
      ],
      "metadata": {
        "id": "ppZTXcRTLt82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize the pixel values to be between 0 and 1\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Reshape data to add a channel dimension (necessary for Conv2D layers)\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQlM-j3JMFqk",
        "outputId": "9f56e807-4e41-4ea3-f903-8d9ead2c3220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from keras_tuner import HyperModel"
      ],
      "metadata": {
        "id": "iBtFXruAM0gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  # Convolutional layers\n",
        "  model.add(layers.Conv2D(\n",
        "      filters = hp.Int('filters', min_value = 32, max_value = 128, step = 32),\n",
        "      kernel_size = hp.Choice('kernel_size', values = [3, 5]),\n",
        "      activation = 'relu',\n",
        "      input_shape = (28, 28, 1)\n",
        "  ))\n",
        "  model.add(layers.MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "  # Additional convolutional layers\n",
        "  model.add(layers.Conv2D(\n",
        "      filters = hp.Int('filters_2', min_value = 32, max_value = 128, step = 32),\n",
        "      kernel_size = hp.Choice('kernel_size_2', values = [3, 5]),\n",
        "      activation = 'relu'\n",
        "  ))\n",
        "  model.add(layers.MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "\n",
        "  # Fully connected layer\n",
        "  model.add(layers.Dense(\n",
        "      units = hp.Int('units', min_value = 32, max_value = 512, step = 32),\n",
        "      activation = 'relu'\n",
        "  ))\n",
        "\n",
        "  # Output layer\n",
        "  model.add(layers.Dense(10, activation = 'softmax'))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(\n",
        "      optimizer = tf.keras.optimizers.Adam(\n",
        "          hp.Choice ('learning_rate', values = [1e-2, 1e-1, 1e-4])\n",
        "      ),\n",
        "      loss = 'sparse_categorical_crossentropy',\n",
        "      metrics = ['accuracy']\n",
        "  )\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "eWf3m8PtM0jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up the Keras Tuner"
      ],
      "metadata": {
        "id": "E2fB7TRiQKiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_tuner import RandomSearch\n",
        "\n",
        "# Define the tuner\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective = 'val_accuracy',\n",
        "    max_trials = 5,\n",
        "    executions_per_trial = 1,\n",
        "    directory = 'my_dir',\n",
        "    project_name = 'fashion_mnist_tuning'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rn7jcWuQAv6",
        "outputId": "978c6ab0-0d71-41d5-d749-a327490170c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Search for the Best Hyperparameters"
      ],
      "metadata": {
        "id": "mxQtETqERYlg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Search for the best hyperparameters\n",
        "tuner.search(x_train, y_train, epochs = 10, validation_split = 0.2)\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials =1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The optimal number of filters in the first Conv2D layer is {best_hps.get('filters')},\n",
        "the kernel size is {best_hps.get('kernel_size')},\n",
        "and the learning rate is {best_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDKcmYNxQAz4",
        "outputId": "cb21e1d1-5648-4843-cd64-22820461acbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 59s]\n",
            "val_accuracy: 0.8970833420753479\n",
            "\n",
            "Best val_accuracy So Far: 0.8970833420753479\n",
            "Total elapsed time: 00h 05m 44s\n",
            "\n",
            "The optimal number of filters in the first Conv2D layer is 64,\n",
            "the kernel size is 3,\n",
            "and the learning rate is 0.0001.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the best Model"
      ],
      "metadata": {
        "id": "tC4uxolvR5hg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model with the best hyperparameters\n",
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Train the model\n",
        "best_model.fit(x_train, y_train, epochs = 10, validation_split = 0.2)\n",
        "\n",
        "# Evaluate on the test data\n",
        "test_loss, test_acc = best_model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6zaX4FRQA2w",
        "outputId": "5331fef6-7f97-4bfd-b421-91ee5a515401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.6798 - loss: 0.9607 - val_accuracy: 0.8232 - val_loss: 0.4811\n",
            "Epoch 2/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8400 - loss: 0.4474 - val_accuracy: 0.8582 - val_loss: 0.4047\n",
            "Epoch 3/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8634 - loss: 0.3921 - val_accuracy: 0.8712 - val_loss: 0.3673\n",
            "Epoch 4/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8728 - loss: 0.3579 - val_accuracy: 0.8712 - val_loss: 0.3628\n",
            "Epoch 5/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8813 - loss: 0.3346 - val_accuracy: 0.8806 - val_loss: 0.3360\n",
            "Epoch 6/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8854 - loss: 0.3160 - val_accuracy: 0.8818 - val_loss: 0.3295\n",
            "Epoch 7/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8921 - loss: 0.2999 - val_accuracy: 0.8907 - val_loss: 0.3046\n",
            "Epoch 8/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8948 - loss: 0.2859 - val_accuracy: 0.8947 - val_loss: 0.2985\n",
            "Epoch 9/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9012 - loss: 0.2717 - val_accuracy: 0.8966 - val_loss: 0.2929\n",
            "Epoch 10/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9074 - loss: 0.2556 - val_accuracy: 0.8989 - val_loss: 0.2844\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8933 - loss: 0.3055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Test accuracy: {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLkpeTSkSVcZ",
        "outputId": "6edb4006-c758-422f-a00a-bd45e0c9e419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.8938999772071838\n"
          ]
        }
      ]
    }
  ]
}